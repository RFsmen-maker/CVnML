{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a671def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710c32c",
   "metadata": {},
   "source": [
    "# 创建数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a606aae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bba6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6274, 0.7230, 0.6684],\n",
      "        [0.9131, 0.1502, 0.2381],\n",
      "        [0.9983, 0.9024, 0.1471],\n",
      "        [0.7256, 0.3625, 0.5515],\n",
      "        [0.2973, 0.8413, 0.7791]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5ebbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a77854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eebe57ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5,3,dtype=torch.float64)  # 通过现有 Tensor 创建，重用已有属性，如 dtype, device\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "692af9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6053,  1.2316, -0.7535],\n",
      "        [-1.2498, -0.0916,  1.5760],\n",
      "        [ 1.8979, -1.2698, -1.5298],\n",
      "        [-0.2312, -0.7656,  0.0452],\n",
      "        [ 0.8130, -0.3428, -1.9855]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "960f8b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n",
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 尺寸都是返回元组 (x,y)\n",
    "print(x.size())\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb49f6",
   "metadata": {},
   "source": [
    "## 常用\n",
    "\n",
    "|函数|功能|\n",
    "|----|----|\n",
    "|Tensor(*sizes)|基础构造|\n",
    "|tensor(data,)|np.array 类似|\n",
    "|ones(*sizes)|全 1|\n",
    "|zeros(*sizes)|全 0|\n",
    "|eye(*sizes)|单位矩，对角线全 1|\n",
    "|arange(s, e, step)|[s, e) 以 step 为步长|\n",
    "|linspace(s, e, steps)|[s, e] 切分成 step 份|\n",
    "|rand / randn(*sizes)| 均匀 / 标准分布|\n",
    "|normal(mean, std) / uniform(from, to)|正态分布 / 均匀分布|\n",
    "|randperm(m)|随机排列|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f867ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
      "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
      "        90, 91, 92, 93, 94, 95, 96, 97, 98])\n"
     ]
    }
   ],
   "source": [
    "A = torch.arange(0,99,1)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8215d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
      "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
      "        42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55.,\n",
      "        56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.,\n",
      "        70., 71., 72., 73., 74., 75., 76., 77., 78., 79., 80., 81., 82., 83.,\n",
      "        84., 85., 86., 87., 88., 89., 90., 91., 92., 93., 94., 95., 96., 97.,\n",
      "        98., 99.])\n"
     ]
    }
   ],
   "source": [
    "A = torch.linspace(0,99,100)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308d3ec0",
   "metadata": {},
   "source": [
    "# 各种操作\n",
    "\n",
    "## 算术\n",
    "+, torch.add(x, y), x.add_(y)\n",
    "\n",
    "## 索引\n",
    "index_select(input, dim, index)  \n",
    "masked_select(input,mask)  \n",
    "non_zero(input)  \n",
    "gather(input,dim,index)  \n",
    "\n",
    "## 改变形状\n",
    "引用的内存在同一块  \n",
    "一维：y = x.view(n)  \n",
    "根据行数推断：z = x.view(-1, n)  \n",
    "不保证返回拷贝：torch.reshape()  \n",
    "用复制代替：y = x.clone().view()  \n",
    "\n",
    "> clone 会记录在计算图中，梯度回传到副本时也会回传到源  \n",
    "\n",
    "直接取 tensor 为普通值：x.item()  \n",
    "\n",
    "\n",
    "## 线性代数\n",
    "|函数|描述|\n",
    "|----|-----|\n",
    "|trace|对角线和（迹）|\n",
    "|diag|对角线元素|\n",
    "|triu / tril|矩阵上 / 下三角|\n",
    "|mm / bmm|矩阵乘法|\n",
    "|addmm / addbmm / addmv / addr / badbmm| 矩阵运算|\n",
    "|t|转置|\n",
    "|dot / cross|内积 / 外积|\n",
    "|inverse|逆矩阵|\n",
    "|svd|奇异值分解|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9e1ffc",
   "metadata": {},
   "source": [
    "## 广播机制\n",
    "形状不同的运算会自动复制\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec873336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[2, 3],\n",
      "        [3, 4],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1,3).view(1,2)\n",
    "y = torch.arange(1,4).view(3,1)\n",
    "print(x, y, x+y, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bbb83f",
   "metadata": {},
   "source": [
    "## 关于内存\n",
    "直接进行运算如 y = x + y 会开辟新内存空间存储，通过 y[:] = x + y, y.add_(x, out=y), torch.add(x, y, out=y) 把运算结果写回 y 内存空间中  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6ee2f7",
   "metadata": {},
   "source": [
    "## Tensor 与 numpy 转换\n",
    "所有在 CPU 上的 Tensor(except CharTensor) 支持与 numpy 相互转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d48c18fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()\n",
    "print(a, b, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80167e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "c = torch.tensor(a)  # 总是进行数据拷贝\n",
    "print(a, b, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ea194",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2e989b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apparently not available for GPU!\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.one_like(x, device=device)\n",
    "    x = x.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))\n",
    "else:\n",
    "    print(\"Apparently not available for GPU!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43af2a2d",
   "metadata": {},
   "source": [
    "# 自动求梯度（Gradient）\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7731248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "None\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)  # 开始追踪所有在 x 上的操作\n",
    "print(x, x.grad_fn, sep='\\n')  # 直接创建，叶子节点，None\n",
    "print(x.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73784349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x0000026D7F5B3B20>\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y, y.grad_fn, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c764b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "tensor(1., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = x.mean()\n",
    "print(z, out, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6d43dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x0000026D7F5B1420>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)  # 改变 requires_grad\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aea15100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标量不需要指定求导变量\n",
    "out.backward()  # out.backward(torch.tensor(1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020f56a",
   "metadata": {},
   "source": [
    "out 关于 x 的梯度：$\\frac{d(out)}{dx}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33daf210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646ddc96",
   "metadata": {},
   "source": [
    "$$\n",
    "o = \\frac{1}{4}\\sum_{i=1}^4z_i = \\frac{1}{4}\\sum_{i=1}^43(x_i+2)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{o}}{\\partial{x_i}}|_{x_i = 1} = \\frac{9}{2} = 4.5\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
